# Cachibot Configuration Example
# Copy to ~/.cachibot.toml or ./cachibot.toml in your workspace

# Instance timezone (IANA name, e.g. "America/New_York", "Europe/London")
# Used for scheduling — cron expressions evaluate in this timezone
# timezone = "UTC"

[agent]
# Model to use (format: provider/model-name)
# Options: moonshot/kimi-k2.5, claude/claude-sonnet-4-20250514, openai/gpt-4o, ollama/llama3.1:8b
model = "moonshot/kimi-k2.5"

# Cheap/fast model for utility tasks (name generation, follow-up questions)
# Falls back to the main model if empty
# utility_model = "anthropic/claude-3-5-haiku-20241022"

# Maximum agent iterations per request
max_iterations = 20

# Require approval for each tool execution
approve_actions = false

# Temperature for LLM responses (0.0 - 1.0)
# Moonshot recommends 0.6 for instant mode, 1.0 for thinking mode
temperature = 0.6

# Maximum output tokens per LLM call
# Higher values allow the agent to write longer files and tool outputs
max_tokens = 4096

# Maximum nested agent depth (Prompture recursion limit)
# Prevents infinite sub-agent loops. Default 5 is safe for normal usage.
# max_depth = 5

[sandbox]
# Allowed Python imports (safe modules only)
# Add more as needed, but be careful with security implications
allowed_imports = [
    "json", "csv", "re", "math", "datetime", "collections",
    "itertools", "functools", "random", "statistics",
    "base64", "hashlib", "copy", "pprint", "typing",
]

# Maximum execution time for Python code (seconds)
timeout_seconds = 30

# Maximum output length (characters)
max_output_length = 10000

[workspace]
# Paths relative to workspace that are allowed
allowed_paths = ["."]

# Patterns to ignore when listing files
ignore_patterns = [
    "node_modules",
    ".git",
    "__pycache__",
    "*.pyc",
    ".env",
    "venv",
    ".venv",
]

[knowledge]
# Target number of words per document chunk
chunk_size = 500

# Number of overlapping words between consecutive chunks
chunk_overlap = 50

# Maximum document chunks returned per query
top_k = 3

# Minimum cosine similarity threshold for document retrieval (0.0 - 1.0)
min_similarity = 0.3

# Embedding model (provider/model format or fastembed name for local fallback)
# Provider models: "openai/text-embedding-3-small", "openai/text-embedding-3-large",
#                  "ollama/nomic-embed-text", "ollama/all-minilm"
# Fastembed (local): "BAAI/bge-small-en-v1.5"
embedding_model = "openai/text-embedding-3-small"

# Maximum recent conversation messages included in context
max_history_messages = 10

[database]
# Database connection URL
# Leave empty for SQLite (default — auto-created at ~/.cachibot/cachibot.db)
# For PostgreSQL: url = "postgresql+asyncpg://user:pass@localhost:5432/cachibot"
# Run 'cachibot setup-db postgres' for guided setup
# url = ""

# Connection pool settings (PostgreSQL only)
# pool_size = 10
# max_overflow = 20
# pool_recycle = 3600

# Echo SQL statements to stdout (debug only)
# echo = false

[display]
# Show agent's thinking process
show_thinking = true

# Show token usage and cost after each response
show_cost = true

# Output style: "detailed" or "compact"
style = "detailed"

[telemetry]
# Enable anonymous usage analytics (opt-in, default: false)
# Set to true to help improve CachiBot by sending anonymous statistics
# See https://cachibot.ai/telemetry for details on what is collected
enabled = false
# install_id = ""  # Auto-generated UUID, do not edit manually
# Override with environment variable: CACHIBOT_TELEMETRY_DISABLED=1
