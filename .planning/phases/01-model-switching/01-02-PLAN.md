---
phase: 01-model-switching
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - cachibot/api/websocket.py
autonomous: true
requirements:
  - MODL-02
  - MODL-03

must_haves:
  truths:
    - "The backend uses the model override from the WebSocket payload for that specific response"
    - "The actual model used is persisted in the assistant message metadata and survives page refresh"
    - "Each chat bubble displays which model produced that response after reloading the page"
  artifacts:
    - path: "cachibot/api/websocket.py"
      provides: "Model metadata persistence in assistant BotMessage save"
      contains: "metadata.*model"
  key_links:
    - from: "cachibot/api/websocket.py"
      to: "cachibot/models/knowledge.py"
      via: "BotMessage metadata dict with model key"
      pattern: 'metadata=.*"model"'
    - from: "cachibot/api/websocket.py"
      to: "cachibot/storage/repository.py"
      via: "save_bot_message persists metadata to DB"
      pattern: "save_bot_message"
---

<objective>
Persist the actual model used for each assistant response in the `BotMessage.metadata` so that model information survives page refresh and is displayed in chat bubbles.

Purpose: Currently, the model name is written to in-memory message metadata via the `usage` WS handler on the frontend, but the backend saves the assistant `BotMessage` with an empty `metadata={}` dict. On page refresh, messages load from the database without model information and the bubble can't display which model was used. This plan fixes the persistence gap.

Output: Updated `websocket.py` where the assistant `BotMessage` save includes `metadata={"model": actual_model}` derived from `run_usage["per_model"]` or the agent's configured model.
</objective>

<execution_context>
@/home/uan/.claude/get-shit-done/workflows/execute-plan.md
@/home/uan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-model-switching/01-RESEARCH.md

@cachibot/api/websocket.py
@cachibot/models/knowledge.py
@cachibot/storage/repository.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Persist actual model in assistant BotMessage metadata</name>
  <files>cachibot/api/websocket.py</files>
  <action>
In `cachibot/api/websocket.py`, in the `run_agent()` function:

1. **Extract actual model from run_usage** — after line 412 (`run_usage = agent_result.run_usage if agent_result else {}`), add:
   ```python
   # Determine the actual model used for this response
   per_model = run_usage.get("per_model", {})
   actual_model = next(iter(per_model), None) or agent.config.agent.model
   ```

   `run_usage["per_model"]` is a dict keyed by model ID (e.g., `{"gpt-4": {...}}`). The first key is the primary model used. If `per_model` is empty (edge case), fall back to `agent.config.agent.model` which is the configured effective model from `build_bot_agent`.

2. **Include model in assistant BotMessage metadata** — in the `BotMessage` constructor for the assistant message (around line 420-428), add the `metadata` field:
   ```python
   assistant_msg = BotMessage(
       id=str(uuid.uuid4()),
       bot_id=bot_id,
       chat_id=chat_id,
       role="assistant",
       content=response_text,
       timestamp=datetime.now(timezone.utc),
       reply_to_id=bot_reply_to,
       metadata={"model": actual_model},
   )
   ```

   The `BotMessage` Pydantic model (`cachibot/models/knowledge.py`) already has `metadata: dict[str, Any] = Field(default_factory=dict)`. The repository's `save_bot_message` already maps `message.metadata` to the ORM's `meta` JSON column. No changes needed to the model or repository — just pass the dict.

**What this fixes:**
- Before: assistant messages saved with `metadata={}` (default). Model info only lived in frontend memory via the `usage` WS handler. Page refresh lost it.
- After: assistant messages saved with `metadata={"model": "gpt-4o"}` (or whatever model was actually used). Frontend loads from DB on refresh and `MessageBubble` already renders `message.metadata.model` in the info panel.

**What NOT to do:**
- Do NOT modify `BotMessage` model in `knowledge.py` — `metadata` field already accepts arbitrary dicts.
- Do NOT modify `save_bot_message` in `repository.py` — it already persists `message.metadata` as JSON.
- Do NOT modify `MessageBubble.tsx` — it already renders `message.metadata.model` when present.
- Do NOT modify the `usage` WS handler in `useWebSocket.ts` — it still works for real-time display; this change ensures DB persistence.
  </action>
  <verify>
1. Run `cd /mnt/c/Users/Juan/Documents/GitHub/CachiBot && python -c "from cachibot.api.websocket import run_agent; print('import ok')"` — confirms no syntax errors.
2. Run `ruff check cachibot/api/websocket.py` — no lint errors.
3. Run `ruff format --check cachibot/api/websocket.py` — formatting is correct.
4. Visually confirm that the `BotMessage` constructor now includes `metadata={"model": actual_model}`.
  </verify>
  <done>
The `run_agent()` function in `websocket.py` extracts the actual model from `run_usage["per_model"]` (with fallback to `agent.config.agent.model`) and includes it as `metadata={"model": actual_model}` in the assistant `BotMessage` save. Model information now persists in the database and survives page refresh, displayed by the existing `MessageBubble` info panel.
  </done>
</task>

</tasks>

<verification>
1. `ruff check cachibot/api/websocket.py` passes
2. `ruff format --check cachibot/api/websocket.py` passes
3. `python -c "from cachibot.api.websocket import run_agent"` succeeds (no import errors)
4. The `BotMessage` constructor for assistant messages includes `metadata={"model": actual_model}`
5. `actual_model` is derived from `run_usage.get("per_model", {})` with fallback to `agent.config.agent.model`
</verification>

<success_criteria>
- Assistant messages are saved with `metadata={"model": "<actual_model_id>"}` in the database
- The model field in metadata reflects the actual model used (from usage stats), not just the configured model
- No changes needed to `BotMessage` model, repository, or `MessageBubble` — they already support this
- Model information persists across page refresh
</success_criteria>

<output>
After completion, create `.planning/phases/01-model-switching/01-02-SUMMARY.md`
</output>
